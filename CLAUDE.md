# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A production-ready PDF RAG (Retrieval-Augmented Generation) system that extracts content from PDFs, indexes it into ChromaDB, and provides an interactive chat interface using Azure OpenAI. The system specializes in handling complex PDFs with mixed content including text, figures, and tables.

## Development Commands

### Environment Setup
```bash
# IMPORTANT: Always use virtual environment for this project
# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip

# Install dependencies
pip install -r requirements.txt
```

### Core Workflows
```bash
# 1. Extract PDF content (parallel processing)
python parallel_pdf_extractor.py <pdf_file>

# 2. Index to ChromaDB with Azure OpenAI embeddings
python index_to_chromadb.py --use-openai --azure

# 3. Interactive chat with PDF
python chat_with_pdf.py

# Single query mode
python rag_query.py "Your question here"

# Clear and reindex (when changing embedding models)
python index_to_chromadb.py --use-openai --azure --clear
```

### Testing & Validation
```bash
# Test extraction on specific page
python extract_all_elements.py single_page.pdf

# Search ChromaDB without indexing
python index_to_chromadb.py --search-only --search "test query"

# Run with verbose output
python rag_query.py --n-results 10 "question"
```

## Architecture & Key Components

### Core Processing Pipeline

The system follows a three-stage pipeline:

1. **PDF Extraction Layer** (`parallel_pdf_extractor.py`)
   - Uses multiprocessing for efficient page-by-page extraction
   - Dual-mode extraction: hi-res for visual detection, fast for clean text
   - Implements 2.78x coordinate scaling between resolution modes
   - Outputs structured metadata.json with text sections, figures, and tables

2. **Vector Indexing Layer** (`index_to_chromadb.py`)
   - `PDFMetadataIndexer` class manages ChromaDB operations
   - Supports both Azure OpenAI and local embeddings (sentence-transformers)
   - Indexes text chunks with page/section metadata
   - Embeds figure/table captions for visual element retrieval

3. **RAG Query Layer** (`rag_query.py`)
   - `RAGQuerySystem` class handles retrieval and generation
   - Maintains conversation history for contextual responses
   - Includes images in prompts for vision-capable models
   - Supports both single queries and interactive chat sessions

### Key Technical Innovations

**Hybrid Extraction Strategy** (`hybrid_pdf_extractor_refactored.py`)
- Discovered 2.78x coordinate scale factor for accurate spatial filtering
- Eliminates OCR artifacts by using fast mode without OCR for text
- Smart classification reclassifies misidentified visual elements
- Spatial filtering removes text within figure/table boundaries

**Azure OpenAI Integration**
- Supports separate endpoints for embeddings and chat/vision
- Handles Azure-specific deployment names and API versions
- Falls back to environment variables for configuration

## Configuration

### Required Environment Variables (.env)
```env
# Embedding endpoint (can be separate from chat)
AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_EMBEDDING_API_KEY=your_key
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Chat/Vision endpoint
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_DEPLOYMENT=gpt-4
AZURE_OPENAI_API_VERSION=2025-01-01-preview
```

### Directory Structure
```
output/                  # Generated by extraction
├── metadata.json       # Structured document data
├── figures/           # Extracted images (PNG)
├── tables/           # Extracted tables (PNG)
└── extracted_content.md  # Markdown version

chroma_db/             # Vector database storage
└── [collection_data]
```

## Interactive Chat Commands

When using `chat_with_pdf.py`:
- `help` - Show available commands
- `status` - Display collection statistics
- `history` - View conversation history
- `reset` - Clear conversation memory
- `verbose` - Toggle detailed output
- `quit/exit` - Exit chat session

## Troubleshooting

### Embedding Dimension Mismatch
```bash
# Clear and reindex with consistent embeddings
python index_to_chromadb.py --use-openai --azure --clear
```

### No Azure Credentials
Verify `.env` file contains all required Azure OpenAI variables and deployment names match your Azure resources.

### PDF Processing Issues
- Ensure Poppler is installed: `brew install poppler` (macOS) or `apt-get install poppler-utils` (Linux)
- For OCR support: `brew install tesseract` or `apt-get install tesseract-ocr`

## GOLDEN RULE for Refactoring

**When refactoring this codebase:**
1. Make changes incrementally, one small piece at a time
2. After each change, run the script to verify output matches 100%
3. Use git commits as checkpoints after each successful change
4. The current output directory is the source of truth - all refactoring must produce identical output
5. Test with `single_page.pdf` to validate changes

**Module dependency chain:**
- `parallel_pdf_extractor.py` → uses → `hybrid_pdf_extractor_refactored.py` → uses → `extract_all_elements.py`

## Key Files Reference

- `parallel_pdf_extractor.py`: Main extraction script with multiprocessing
- `index_to_chromadb.py`: ChromaDB indexing with embedding support
- `rag_query.py`: Core RAG system implementation
- `chat_with_pdf.py`: Interactive chat interface
- `hybrid_pdf_extractor_refactored.py`: Advanced extraction with spatial filtering
- `extract_all_elements.py`: Reference implementation for testing