# PDF RAG Chat System

## Overview

A complete Retrieval-Augmented Generation (RAG) system for chatting with PDF documents using Azure OpenAI. The system extracts text, figures, and tables from PDFs, indexes them in ChromaDB, and provides an interactive chat interface with vision capabilities.

## ğŸš€ Quick Start

```bash
# 1. Setup environment
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configure Azure OpenAI
cp .env.example .env
# Edit .env with your credentials

# 3. Process PDF and chat (all-in-one)
python pdf_chat_pipeline.py document.pdf

# Or run steps individually:
# python extractors/parallel_pdf_extractor.py document.pdf
# python rag/index_to_chromadb.py --use-openai --azure
# python rag/chat_with_pdf.py
```

## âœ¨ Key Features

- **ğŸ¯ One-Command Pipeline**: Extract, index, and chat with `pdf_chat_pipeline.py`
- **ğŸ“„ PDF Processing**: Parallel extraction of text, figures, and tables
- **ğŸ” Semantic Search**: Vector-based retrieval using ChromaDB
- **ğŸ–¼ï¸ Vision Support**: Includes images in queries for visual Q&A
- **ğŸ’¬ Conversation Memory**: Maintains context across questions
- **ğŸš€ Azure OpenAI**: Supports separate endpoints for embeddings and chat
- **ğŸ“Š Rich UI**: Progress bars and formatted output with rich library

## ğŸ“ Project Structure

```
app_new/
â”œâ”€â”€ pdf_chat_pipeline.py         # ğŸ¯ Main unified pipeline script
â”œâ”€â”€ extract_pdf.py              # Entry point for extraction
â”‚
â”œâ”€â”€ extractors/                 # PDF extraction modules
â”‚   â”œâ”€â”€ pdf_hybrid_extractor.py
â”‚   â”œâ”€â”€ pdf_simple_extractor.py
â”‚   â””â”€â”€ parallel_pdf_extractor.py
â”‚
â”œâ”€â”€ core/                       # Core configuration and models
â”‚   â”œâ”€â”€ pdf_extraction_config.py
â”‚   â””â”€â”€ pdf_extraction_models.py
â”‚
â”œâ”€â”€ processors/                 # Processing components
â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”œâ”€â”€ image_extractor.py
â”‚   â”œâ”€â”€ table_exporter.py
â”‚   â””â”€â”€ element_preprocessor.py
â”‚
â”œâ”€â”€ classifiers/               # Element classification
â”‚   â”œâ”€â”€ element_classifier_simple.py
â”‚   â””â”€â”€ element_classifier_hybrid.py
â”‚
â”œâ”€â”€ utils/                     # Utility functions
â”‚   â”œâ”€â”€ bbox_operations.py
â”‚   â”œâ”€â”€ caption_detector.py
â”‚   â”œâ”€â”€ file_manager.py
â”‚   â””â”€â”€ parallel_combiner.py
â”‚
â”œâ”€â”€ output/                    # Output generation code
â”‚   â”œâ”€â”€ document_structure.py
â”‚   â””â”€â”€ markdown_generator.py
â”‚
â”œâ”€â”€ rag/                       # RAG system components
â”‚   â”œâ”€â”€ index_to_chromadb.py
â”‚   â”œâ”€â”€ rag_query.py
â”‚   â””â”€â”€ chat_with_pdf.py
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ README.md
    â”œâ”€â”€ PIPELINE_USAGE.md
    â””â”€â”€ PROJECT_STRUCTURE.md
```

## ğŸ› ï¸ Components

### 1. PDF Extraction (`parallel_pdf_extractor.py`)
- Uses parallel processing for speed
- Extracts text with structure preservation
- Saves figures and tables as PNG images
- Generates comprehensive metadata

### 2. Vector Indexing (`index_to_chromadb.py`)
- Indexes text sections and visual elements
- Uses figure/table captions for embeddings
- Supports Azure OpenAI and local embeddings

### 3. RAG System (`rag_query.py`)
- Retrieves relevant content from ChromaDB
- Includes images in vision-capable models
- Maintains conversation history

### 4. Chat Interface (`chat_with_pdf.py`)
- Interactive command-line interface
- Conversation memory for context
- Built-in commands for control

## ğŸ’¬ Chat Commands

- `help` - Show available commands
- `status` - Display collection statistics
- `history` - View conversation history
- `reset` - Clear conversation memory
- `verbose` - Toggle detailed output
- `quit` - Exit chat

## ğŸ“‹ Requirements

### Software
- Python 3.8+
- Poppler (for PDF processing)
- Tesseract OCR (optional)

### Azure OpenAI
- Embedding model (e.g., text-embedding-ada-002)
- Chat model with vision (e.g., gpt-4)

## ğŸ”§ Configuration

Create `.env` from template:

```env
# Embeddings
AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_EMBEDDING_API_KEY=your_key
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Chat/Vision
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_DEPLOYMENT=gpt-4
```

## ğŸ“š Documentation

- **[RAG_USAGE.md](RAG_USAGE.md)** - Detailed usage instructions
- **[README_EXTRACTION.md](README_EXTRACTION.md)** - PDF extraction details

## ğŸ› Troubleshooting

### Common Issues

1. **Embedding dimension mismatch**
   ```bash
   python index_to_chromadb.py --clear --use-openai --azure
   ```

2. **No images in responses**
   - Verify Azure model supports vision
   - Check images exist in `output/figures/`

3. **API errors**
   - Verify `.env` configuration
   - Check deployment names

## ğŸ“ License

This project is for demonstration and educational purposes.